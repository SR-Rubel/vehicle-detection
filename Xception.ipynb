{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Xception.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"lQIwqFBjYhEh"},"source":["import sys\n","import os\n","from keras.layers import *\n","from keras.optimizers import *\n","from keras.applications import *\n","from keras.models import Model\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from keras import backend as k\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1L46v2W-Y7sV"},"source":["# fix seed for reproducible results (only works on CPU, not GPU)\n","# seed = 9\n","# np.random.seed(seed=seed)\n","# tf.set_random_seed(seed=seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b2e0bJK7SbUy","executionInfo":{"elapsed":23284,"status":"ok","timestamp":1634458611401,"user":{"displayName":"The Black","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10955237020340772162"},"user_tz":-360},"outputId":"703fae75-4de9-4ff3-d455-7818790b0238"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"Y6Ep7m2HY-og"},"source":["# hyper parameters for model\n","nb_classes = 2  # number of classes\n","based_model_last_block_layer_number = 126  # value is based on based model selected.\n","img_width, img_height = 299, 299  # change based on the shape/structure of your images\n","batch_size = 32  # try 4, 8, 16, 32, 64, 128, 256 dependent on CPU/GPU memory capacity (powers of 2 values).\n","nb_epoch = 50  # number of iteration the algorithm gets trained.\n","learn_rate = 1e-4  # sgd learning rate\n","momentum = .9  # sgd momentum to avoid local minimum\n","transformation_ratio = .05  # how aggressive will be the data augmentation/transformation"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qKtR2sNWP8HT","executionInfo":{"elapsed":398,"status":"ok","timestamp":1634459489885,"user":{"displayName":"The Black","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10955237020340772162"},"user_tz":-360},"outputId":"688d4f7f-274d-4475-ff49-467552ce7ac0"},"source":["# Part 1 - Data Preprocessing\n","input_shape=(299,299)\n","\n","# Preprocessing the Training set\n","train_datagen = ImageDataGenerator(rescale = 1./255,\n","                                  rotation_range=40,\n","                                  width_shift_range=0.2,\n","                                  height_shift_range=0.2,\n","                                  shear_range=0.2,\n","                                  zoom_range=0.2,\n","                                  horizontal_flip=True,\n","                                  fill_mode='nearest')\n","training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/splited_train_test_poribohon_data/train',\n","                                                 target_size =input_shape,\n","                                                 batch_size = 64,\n","                                                 shuffle = True,\n","                                                 class_mode = 'categorical')\n","\n","# Preprocessing the Test set\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/splited_train_test_poribohon_data/test',\n","                                            target_size = input_shape\n","                                            )"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Found 6541 images belonging to 15 classes.\n","Found 832 images belonging to 15 classes.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wg19jN08bNji","executionInfo":{"elapsed":1942,"status":"ok","timestamp":1634459655430,"user":{"displayName":"The Black","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10955237020340772162"},"user_tz":-360},"outputId":"872d1320-8847-42d0-986d-91c5c057066f"},"source":["base_model = tf.keras.applications.Xception(input_shape=(img_width, img_height, 3), weights='imagenet', include_top=False)\n","\n","# Top Model Block\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","predictions = Dense(15, activation='softmax')(x)\n","\n","# add your top layer block to your base model\n","model = Model(base_model.input, predictions)\n","print(model.summary())"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            [(None, 299, 299, 3) 0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_2[0][0]                    \n","__________________________________________________________________________________________________\n","block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n","__________________________________________________________________________________________________\n","block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 74, 74, 128)  512         conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 74, 74, 128)  0           block2_pool[0][0]                \n","                                                                 batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add_12[0][0]                     \n","__________________________________________________________________________________________________\n","block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 37, 37, 256)  32768       add_12[0][0]                     \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 37, 37, 256)  1024        conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, 37, 37, 256)  0           block3_pool[0][0]                \n","                                                                 batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_13[0][0]                     \n","__________________________________________________________________________________________________\n","block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 19, 19, 728)  186368      add_13[0][0]                     \n","__________________________________________________________________________________________________\n","block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 19, 19, 728)  2912        conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, 19, 19, 728)  0           block4_pool[0][0]                \n","                                                                 batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_14[0][0]                     \n","__________________________________________________________________________________________________\n","block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n","                                                                 add_14[0][0]                     \n","__________________________________________________________________________________________________\n","block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_15[0][0]                     \n","__________________________________________________________________________________________________\n","block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_16 (Add)                    (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n","                                                                 add_15[0][0]                     \n","__________________________________________________________________________________________________\n","block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_16[0][0]                     \n","__________________________________________________________________________________________________\n","block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_17 (Add)                    (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n","                                                                 add_16[0][0]                     \n","__________________________________________________________________________________________________\n","block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_17[0][0]                     \n","__________________________________________________________________________________________________\n","block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_18 (Add)                    (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n","                                                                 add_17[0][0]                     \n","__________________________________________________________________________________________________\n","block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_18[0][0]                     \n","__________________________________________________________________________________________________\n","block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_19 (Add)                    (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n","                                                                 add_18[0][0]                     \n","__________________________________________________________________________________________________\n","block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_19[0][0]                     \n","__________________________________________________________________________________________________\n","block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_20 (Add)                    (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n","                                                                 add_19[0][0]                     \n","__________________________________________________________________________________________________\n","block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_20[0][0]                     \n","__________________________________________________________________________________________________\n","block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_21 (Add)                    (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n","                                                                 add_20[0][0]                     \n","__________________________________________________________________________________________________\n","block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_21[0][0]                     \n","__________________________________________________________________________________________________\n","block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_22 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n","                                                                 add_21[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_22[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 10, 10, 1024) 745472      add_22[0][0]                     \n","__________________________________________________________________________________________________\n","block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 10, 10, 1024) 4096        conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","add_23 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n","                                                                 batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","block14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_23[0][0]                     \n","__________________________________________________________________________________________________\n","block14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","global_average_pooling2d_1 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 15)           30735       global_average_pooling2d_1[0][0] \n","==================================================================================================\n","Total params: 20,892,215\n","Trainable params: 20,837,687\n","Non-trainable params: 54,528\n","__________________________________________________________________________________________________\n","None\n"]}]},{"cell_type":"code","metadata":{"id":"rn4JjlaHNx4F"},"source":["for layer in base_model.layers:\n","    layer.trainable = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xTbvXFCRbUG7"},"source":["model.compile(optimizer='nadam',\n","                loss='categorical_crossentropy',  # categorical_crossentropy if multi-class classifier\n","                metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZYvumVoROeZC"},"source":["top_weights_path = os.path.join('/content/drive/MyDrive/Xception_weights', 'top_model_weights.h5')\n","callbacks_list = [\n","    ModelCheckpoint(top_weights_path, monitor='val_acc', verbose=1, save_best_only=True),\n","    EarlyStopping(monitor='val_acc', patience=5, verbose=0)\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DBPhR4idgXB8"},"source":["**From transfer learning we find(after 20 ephocs)** accuracy: 0.9330 - val_loss: 0.1846 - val_accuracy: 0.9387"]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"tqPLjEv5PlaZ","outputId":"81969754-5501-4131-b142-f5fb55abf4fb"},"source":["model.fit(x=training_set,\n","                    # samples_per_epoch=train_generator.nb_sample,\n","                    # nb_epoch=nb_epoch / 5,\n","                    validation_data=test_set,\n","                    initial_epoch=5,\n","                    # nb_val_samples=validation_generator.nb_sample,\n","                    epochs=25,callbacks=callbacks_list)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 6/25\n"," 17/103 [===>..........................] - ETA: 8:26 - loss: 0.3355 - accuracy: 0.9026"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"name":"stdout","output_type":"stream","text":["103/103 [==============================] - 709s 7s/step - loss: 0.3671 - accuracy: 0.8858 - val_loss: 0.2488 - val_accuracy: 0.9267\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 7/25\n","103/103 [==============================] - 701s 7s/step - loss: 0.3424 - accuracy: 0.9018 - val_loss: 0.2494 - val_accuracy: 0.9279\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 8/25\n","103/103 [==============================] - 695s 7s/step - loss: 0.3189 - accuracy: 0.9018 - val_loss: 0.2271 - val_accuracy: 0.9279\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 9/25\n","103/103 [==============================] - 692s 7s/step - loss: 0.3124 - accuracy: 0.9070 - val_loss: 0.2238 - val_accuracy: 0.9303\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 10/25\n","103/103 [==============================] - 692s 7s/step - loss: 0.3041 - accuracy: 0.9084 - val_loss: 0.2216 - val_accuracy: 0.9339\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 11/25\n","103/103 [==============================] - 693s 7s/step - loss: 0.2838 - accuracy: 0.9153 - val_loss: 0.2162 - val_accuracy: 0.9339\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 12/25\n","103/103 [==============================] - 701s 7s/step - loss: 0.2829 - accuracy: 0.9153 - val_loss: 0.2083 - val_accuracy: 0.9291\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 13/25\n","103/103 [==============================] - 717s 7s/step - loss: 0.2762 - accuracy: 0.9177 - val_loss: 0.2018 - val_accuracy: 0.9339\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 14/25\n","103/103 [==============================] - 695s 7s/step - loss: 0.2637 - accuracy: 0.9225 - val_loss: 0.1986 - val_accuracy: 0.9339\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 15/25\n","103/103 [==============================] - 690s 7s/step - loss: 0.2599 - accuracy: 0.9220 - val_loss: 0.1983 - val_accuracy: 0.9375\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 16/25\n","103/103 [==============================] - 697s 7s/step - loss: 0.2465 - accuracy: 0.9255 - val_loss: 0.1938 - val_accuracy: 0.9363\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 17/25\n","103/103 [==============================] - 693s 7s/step - loss: 0.2496 - accuracy: 0.9234 - val_loss: 0.1942 - val_accuracy: 0.9399\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 18/25\n","103/103 [==============================] - 697s 7s/step - loss: 0.2361 - accuracy: 0.9288 - val_loss: 0.1880 - val_accuracy: 0.9387\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 19/25\n","103/103 [==============================] - 689s 7s/step - loss: 0.2373 - accuracy: 0.9266 - val_loss: 0.1924 - val_accuracy: 0.9399\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 20/25\n","103/103 [==============================] - 680s 7s/step - loss: 0.2247 - accuracy: 0.9330 - val_loss: 0.1846 - val_accuracy: 0.9387\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 21/25\n"," 58/103 [===============>..............] - ETA: 4:32 - loss: 0.2394 - accuracy: 0.9254"]}]},{"cell_type":"code","metadata":{"id":"uDyPltCCt9HM"},"source":["model.save_weights('/content/drive/MyDrive/Xception_weights/onlyweigth2.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"0whGtJsFvdVd","executionInfo":{"elapsed":373,"status":"ok","timestamp":1634465607432,"user":{"displayName":"The Black","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10955237020340772162"},"user_tz":-360},"outputId":"736c57b2-1461-4858-f286-0971e3d8905e"},"source":["top_weights_path"],"execution_count":null,"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/Xception_weights/top_model_weights.h5'"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"UBIKwY9KZ-CC"},"source":["# **Fine Tuning part**"]},{"cell_type":"code","metadata":{"id":"gavko1bVUfhY"},"source":["model.load_weights('/content/drive/MyDrive/Xception_weights/onlyweigth2.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nwv8tnhTW3vk"},"source":[" for layer in model.layers[:based_model_last_block_layer_number]:\n","        layer.trainable = False\n","    for layer in model.layers[based_model_last_block_layer_number:]:\n","        layer.trainable = True\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8W4AF-ncW305"},"source":["model.compile(optimizer='nadam',\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aXRenu7xW35j"},"source":["# save weights of best training epoch: monitor either val_loss or val_acc\n","final_weights_path = os.path.join(os.path.abspath(model_path), 'model_weights.h5')\n","callbacks_list = [\n","    ModelCheckpoint(final_weights_path, monitor='val_acc', verbose=1, save_best_only=True),\n","    EarlyStopping(monitor='val_loss', patience=5, verbose=0)\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A6Ucn_RJW4Ca"},"source":["# fine-tune the model\n","model.fit(training_set,\n","                    # samples_per_epoch=train_generator.nb_sample,\n","                    nb_epoch=25,\n","                    validation_data=test_set,\n","                    # nb_val_samples=validation_generator.nb_sample,\n","                    callbacks=callbacks_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ynKx6oZWW4F7"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vwSgAuUUYxSU"},"source":["\n","\n","\n","\n","\n","def train(train_data_dir, validation_data_dir, model_path):\n","    # Pre-Trained CNN Model using imagenet dataset for pre-trained weights\n","    base_model = Xception(input_shape=(img_width, img_height, 3), weights='imagenet', include_top=False)\n","\n","    # Top Model Block\n","    x = base_model.output\n","    x = GlobalAveragePooling2D()(x)\n","    predictions = Dense(nb_classes, activation='softmax')(x)\n","\n","    # add your top layer block to your base model\n","    model = Model(base_model.input, predictions)\n","    print(model.summary())\n","\n","    # # let's visualize layer names and layer indices to see how many layers/blocks to re-train\n","    # # uncomment when choosing based_model_last_block_layer\n","    # for i, layer in enumerate(model.layers):\n","    #     print(i, layer.name)\n","\n","    # first: train only the top layers (which were randomly initialized)\n","    # i.e. freeze all layers of the based model that is already pre-trained.\n","    for layer in base_model.layers:\n","        layer.trainable = False\n","\n","    # Read Data and Augment it: Make sure to select augmentations that are appropriate to your images.\n","    # To save augmentations un-comment save lines and add to your flow parameters.\n","    train_datagen = ImageDataGenerator(rescale=1. / 255,\n","                                       rotation_range=transformation_ratio,\n","                                       shear_range=transformation_ratio,\n","                                       zoom_range=transformation_ratio,\n","                                       cval=transformation_ratio,\n","                                       horizontal_flip=True,\n","                                       vertical_flip=True)\n","\n","    validation_datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","    os.makedirs(os.path.join(os.path.abspath(train_data_dir), '../preview'), exist_ok=True)\n","    train_generator = train_datagen.flow_from_directory(train_data_dir,\n","                                                        target_size=(img_width, img_height),\n","                                                        batch_size=batch_size,\n","                                                        class_mode='categorical')\n","    # save_to_dir=os.path.join(os.path.abspath(train_data_dir), '../preview')\n","    # save_prefix='aug',\n","    # save_format='jpeg')\n","    # use the above 3 commented lines if you want to save and look at how the data augmentations look like\n","\n","    validation_generator = validation_datagen.flow_from_directory(validation_data_dir,\n","                                                                  target_size=(img_width, img_height),\n","                                                                  batch_size=batch_size,\n","                                                                  class_mode='categorical')\n","\n","    model.compile(optimizer='nadam',\n","                  loss='categorical_crossentropy',  # categorical_crossentropy if multi-class classifier\n","                  metrics=['accuracy'])\n","\n","    # save weights of best training epoch: monitor either val_loss or val_acc\n","\n","    top_weights_path = os.path.join(os.path.abspath(model_path), 'top_model_weights.h5')\n","    callbacks_list = [\n","        ModelCheckpoint(top_weights_path, monitor='val_acc', verbose=1, save_best_only=True),\n","        EarlyStopping(monitor='val_acc', patience=5, verbose=0)\n","    ]\n","\n","    # Train Simple CNN\n","    model.fit_generator(train_generator,\n","                        samples_per_epoch=train_generator.nb_sample,\n","                        nb_epoch=nb_epoch / 5,\n","                        validation_data=validation_generator,\n","                        nb_val_samples=validation_generator.nb_sample,\n","                        callbacks=callbacks_list)\n","\n","    # verbose\n","    print(\"\\nStarting to Fine Tune Model\\n\")\n","\n","    # add the best weights from the train top model\n","    # at this point we have the pre-train weights of the base model and the trained weight of the new/added top model\n","    # we re-load model weights to ensure the best epoch is selected and not the last one.\n","    model.load_weights(top_weights_path)\n","\n","    # based_model_last_block_layer_number points to the layer in your model you want to train.\n","    # For example if you want to train the last block of a 19 layer VGG16 model this should be 15\n","    # If you want to train the last Two blocks of an Inception model it should be 172\n","    # layers before this number will used the pre-trained weights, layers above and including this number\n","    # will be re-trained based on the new data.\n","    for layer in model.layers[:based_model_last_block_layer_number]:\n","        layer.trainable = False\n","    for layer in model.layers[based_model_last_block_layer_number:]:\n","        layer.trainable = True\n","\n","    # compile the model with a SGD/momentum optimizer\n","    # and a very slow learning rate.\n","    model.compile(optimizer='nadam',\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    # save weights of best training epoch: monitor either val_loss or val_acc\n","    final_weights_path = os.path.join(os.path.abspath(model_path), 'model_weights.h5')\n","    callbacks_list = [\n","        ModelCheckpoint(final_weights_path, monitor='val_acc', verbose=1, save_best_only=True),\n","        EarlyStopping(monitor='val_loss', patience=5, verbose=0)\n","    ]\n","\n","    # fine-tune the model\n","    model.fit_generator(train_generator,\n","                        samples_per_epoch=train_generator.nb_sample,\n","                        nb_epoch=nb_epoch,\n","                        validation_data=validation_generator,\n","                        nb_val_samples=validation_generator.nb_sample,\n","                        callbacks=callbacks_list)\n","\n","    # save model\n","    model_json = model.to_json()\n","    with open(os.path.join(os.path.abspath(model_path), 'model.json'), 'w') as json_file:\n","        json_file.write(model_json)\n","\n","\n","if __name__ == '__main__':\n","    if not len(sys.argv) == 3:\n","        print('Arguments must match:\\npython code/train.py <data_dir/> <model_dir/>')\n","        print('Example: python code/train.py data/dogs_cats/ model/dog_cats/')\n","        sys.exit(2)\n","    else:\n","        data_dir = os.path.abspath(sys.argv[1])\n","        train_dir = os.path.join(os.path.abspath(data_dir), 'train')  # Inside, each class should have it's own folder\n","        validation_dir = os.path.join(os.path.abspath(data_dir), 'validation')  # each class should have it's own folder\n","        model_dir = os.path.abspath(sys.argv[2])\n","\n","        os.makedirs(os.path.join(os.path.abspath(data_dir), 'preview'), exist_ok=True)\n","        os.makedirs(model_dir, exist_ok=True)\n","\n","    train(train_dir, validation_dir, model_dir)  # train model\n","\n","    # release memory\n","    k.clear_session()"],"execution_count":null,"outputs":[]}]}